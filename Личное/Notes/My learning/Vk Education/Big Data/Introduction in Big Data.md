
## Main Concepts (5V)

1. Volume (как много храним)
2. Variety (разные виды данных)
3. Velocity (как много доставляем и как быстро процессим)
4. Value (ценность данных)
5. Veracity (надёжность + достоверность и этика (?))

	 __Variety__:
	 - Структурированные днные: организованные, маркированные и легконаходимые данные. Например, данные в реляционных базах данных и электронных таблицах.
	 - Полуструктурированные данные: содержат структурированные элементы, но не имеют жесткой структуры. Например, файлы XML, в сообщения электронной почты и данные в формате JSON.
	 - Неструктурированные данные: не имеют определенной формы или структуры и часто представляют собой тексты, видео, веб-страницы и т.д.

# Evolution of systems storage data

#### RDBMS (Relation Database Management System)

 - Храним и читаем данные построчно
 - Жёсткая структура хранимых данных
 - ACID (atomicity - атомарность, consistency - согласованность, isolation - изолированность, durability - стойкость)

Примерами служат: MySQL, PostgreSQL, Oracle DB

#### NoSColumn-oriented DBMS

- Храним и читаем данные в колонках
- Эффективнее работаем с большими таблицами
- Эффективное сжатие
- Лучше, чем классические RDBMS, подходит для аналитики

Примеры: ClickHouse, druid, Amazon Redshift

#### NoSQL

Not Only SQL | Фокус на горизонтальную масштабируемость. Репликация и шардинг.

Семейства:
- `Key-value`: MemcacheDB, Redis, Riak, Amazon DynamoDB
- `Column` : Apache HBase, Apache Cassandra, ScyllaDB
- `Document`: СУБД CouchDB, Couchbase, MongoDB, BerkeleyDB XML
- `Graph`: Neo4j, OrientDB, AllegroGraph, Blazegraph, IfiniteGraph

>[!note] Репликация
> Ситуация когда данные могут храниться распределено и она должна храниться несколько раз. Иными словами, думаю для более простого понимания (бекап)

>[!note] Шардинг 
> Это когда мы можем наши данные поделить по определенному паддингу. К примеру есть сенсор погоды и есть какие-то ID, то если это ID%3 == 0 -> поедут в Shard_1, и в зависимости от остатка относить их в шарды. Так мы можем равномерно распределить наши данные. Ну и также реализуем на чтение на этапе реализации логики


#### NoSQL. CAP

__Теорема CAP__ - в любой реализации распределённых вычислений возможно обеспечить __не более двух__ из трёх свойств:

- согласованность данных (__consistency__) - во всех вычислительных узлах в один момент времени данные не противоречат друг другу
- доступность (__availability__) - любой запрос к распределённой системе завершается корректным откликом, однако без гарантии, что все ответы всех узлов системы совпадают
- устойчивость к разделению (__partition tolerance__) - расщепление распределённой системы на несколько изолированных секций не приводит к некорректности отклика от каждой из секций.

Обычно __partition tolerance__ не жертвуют и выбирают из оставшихся двух. Однако все зависит от ситуации.

#### NoSQL. BASE (ACID в парадигме NoSQL)

- Базовая доступность (__basic availability__) - каждый запрос гарантированно завершается (успешно или безуспешно)
- Гибкое состояние (__soft state__) - состояние системы может изменяться со временем, даже без ввода новых данных, для достижения согласования данных
- Согласованность в конечном счёте (__eventual consistency__)

#### NoSQL. Apache Cassandra

Промышленные решения на базе Cassandra развёрнуты у Netflix, Cisco, IBM, Reddit, Apple, Twitter (X), Spotify и в Одноклассниках (они живи?)

__Особенности__:
- Высокая скорость записи (около 80-360 Мб/с на узел) - данные хранятся в оперативной памяти ответственного узла, и любые обновления сперва выполняются в памяти, а только потом в файловой системе
- Гибкая масштабируемость - можно построить кластер даже на сотню узлов, способный обрабатывать петабайты данных

Стоит отметить, что Cassandra довольно зрелый проект, который давно на рынке. Пользуются ей, потому что она позволяет развернуть кластер на петабайты данных и ее легко обслуживать. Дело в том, что большинство проблем заключаются как раз в поддержке, из-за того что Node меняются, слетают и т.п.

![[Pasted image 20250121004247.png]]

#### Message broker

Довольно специфическая система хранения данных. Она отличается тем, что чаще всего она является некоторой промежуточной системой хранения данных. Её особенность заключается в том, что её можно быстро поднять и также быстро передать данные. Их существует большое количество. Каждый имеет свои особенности, но у каждой из них есть шардинг и репликация, однако, повторимся, обладают специфическим устройством.

Временное хранение данных. Репликация и шардинг.

- Apache Kafka
- Apache Pulsar
- RabbitMQ
- Amazon Web Services (AWS) Kinesis

Для чего подойдет Apache Kafka:
- для логирования поведения пользователя на сайте
- обработки потоков информации с конечных устройств IoT и IIoT (сырые данные)
- журналирование событий

Состоит из брокеров, консюмеров и продюсеров. Данные разделяются по топикам.

#### Feature Storage
(Используется для ML моделей каких-то)
__Что?__ Хранит и готовит фичи для моделей

__Зачем?__ Переиспользование фич и быстрая выкатка новых моделей

![[Pasted image 20250121005016.png]]

Здесь мы можем увидеть несколько интересных моментов. Здесь очень мало фичей с открытым исходным кодом. Очень многие из них, даже если открытые, то они поставляются вендером и есть свои подводные камни. Если же посмотреть на то где они хранят свои данные, то можно заметить, что они исползуют очень много OpenSource систем и довольно понятных инструментов. 

В общем и целом, довольно специфичное хранилище тоже.


#### ETL

![[Pasted image 20250121005523.png]]

Это процесс, который позволяет нам взять данные откуда мы хотим и положить в другое место для последующего анализа или аналитики. Встречается очень часто

## Распределённая файловая система HDFS

#### MPP & Distributed Computing (Distributed Processing)

Параллельные вычисления:
- Shared memory
- Fail-stop
- Sync
- Scientific tasks

![[Pasted image 20250121010025.png]]

Распределённые вычисления:
- Distrivuted memory
- Fail tolernce
- Async
- Cost / performance balance

![[Pasted image 20250121005940.png]]


#### GSF -> HDFS

Hadoop

- 2003г. Опубликована статья про GFS
- 2006г. Выпущена первая версия hadoop
- 2010г. Facebook построила крупнейший кластер Hadoop с объёмом хранения 21 Пбайт
- 2012г. Facebook расширила кластер до 100 Пбайт
- 2013г. Более 50 компаний используют Hadoop

#### Архитектура HDFS

__NameNode__:
- Хранит пространства имён
- Хранит расположение блоков файлов
- Ведёт журнал изменений на диске
- SPoF

__DataNode__:
- Непосредственно хранит данные
- Отчитывается о своём состоянии Namenode

![[Pasted image 20250121010515.png]]


DataNode знает о блоках. Блоки - самая маленькая единица для хранения в HDFS. Любые данные попадающие в HDFS, идут в блоки. Ну и далее идет расчет и их расположение в памяти.

Rack - стойки на которых располагаются сервера. У нас есть два сервера. Они хранят внутри себя блоки, эти блоки реплцируются между серверами. Первое свойство распределенных систем, то что они необходимо и возможно реализуют реплицирование данных на разных серверах или дисках. Чтобы данные этого блока были сохранны.

Фактор репликации - определение сколько раз будет записан тот или иной кусочек и мы можем размазать некоторые файл по всему кластеру и также его собрать.
#### Hadoop Architecture and Limitations

__Файл в HDFS__ - запись в метаданных NameNode. Содержимое файла хранится в нескольких блоках одинакового размера.

__Блок__ - базовая и минимальная единица памяти для HDFS. Обычно 128 Мб

- DataNode можно запускать на слабом железе

- Нельзя хранить много файлов (миллиарды - уже проблема), так как описание каждого файла, директории или блока (150 байт) хранится в ОЗУ NameNode.
- Нельзя читать быстро (low-latency)
- Нельзя писать многопоточно

#### Hadoop. Secondar NameNode

![[Pasted image 20250121011431.png]]

В обычном режиме __не дублирует__, а занимается мержем журнала изменений с fsimage для быстрого восстановления NameNode после ребута

В режиме HA (High Availability) может быть два режима:
1. active - текущая ведущая нода
2. standby - нода станет ведущей при выходе из строя активной

__NameNode Federation__ - горизонтальное масштабирование NameNode


#### Hadoop. Чтение

![[Pasted image 20250121011501.png]]

Есть клиент, который идет в HDFS (клиентская нода). Обращается к NameNode, потом открывается InputStream, куда записываются данные из нод, из одной и других, потом он совмещается и поток закрывается.

#### Hadoop. Написание

![[Pasted image 20250121011622.png]]

Поскольку у нас есть репликация, мы должны убедиться, что файл корректно записался на все реплики. После того, как мы записали все это в одну DataNode, он их реплицирует на другие, потом они присылают так называемый AK-package. На самом деле это довольно распространенное обозначение для распределенных систем, что показывает успешность операции. Тогда мы сообщаем нашей NameNode, об успешной операции для дальнейших взаимодействий.

#### Hadoop. Locality & Distances

![[Pasted image 20250121011845.png]]


Посмотрим и узнаем, какие здесь есть свои tradeoff. Вообще давно говорили о Datalocality, когда были медленные сети и диски. Было очень важно код нашего приложения, которые будет работать с данными, подвинуть как можно ближе к нашим данным (На близкий сервер или лучше тот же диск (сервер )). 

#### Keys

![[Pasted image 20250121012746.png]]

Изначально было придумано для телекоммуникаций - помехоустойчивое кодирование.
__Помехоустойчивое кодирование__ - это определенным образом добавлять данные к нашим данным, таким образом, чтобы учитывая потерю данных, мы могли их восстановить из-за чего мы можем их восстановить, но хранимый объем меньше.

#### Apache Parquet

![[Pasted image 20250121013153.png]]

Особенности:
- Один из самых популярных форматов для записи больших данных
- Колоночный тип
- Поддерживает вложенность без потери эффективности
- Пишет схему в футер
- Использует дельта-кодирование, run-length encoding, кодирование по словарю

__Устроено вот так__

![[Pasted image 20250121013333.png]]

Восстанавливает и читает целые колонки

#### Apache Avro

![[Pasted image 20250121013405.png]]

Основное преимущество - она нативно поддерживает революцию схемы. Описывает некоторую сериализацию данных, как их хранить.

#### HDFS API

У HDFS есть несколько API:
- libhdfs - С API
- FileSystem - Java API
- WebHDFS/HttpFS - REST API
- HDFS CLI
Для Python очень удобен __Apache Arrow__

#### Apache Arrow

![[Pasted image 20250121013734.png]]

Очень быстрый, с единым форматом памяти.

## Объектные хранилища

#### Object Storage

Чаще всего речь идет об S3 (некоторый стандарт в общем и целом)

Особенности:
- Архитектурно неограниченный объем хранения (петабайты)
- Высокая доступность данных
- Высокая надежность хранения данных
- Возможность многомерного масштабирования платформы: и вертикального, и горизонтального

Подходит для хранения:
- текста, фото-, видео- и аудиофайлов
- логов и отчётов
- статических компонентов сайтов

![[Pasted image 20250121014237.png]]


Примеры объектных хранилищ:
- Amazon S3
- Google Cloud Storage
- Azure Blob Storage
- MiniO
- Ceph

![[Pasted image 20250121014333.png]]

Формат открытый и описан довольно хорошо. Хранятся в bucket-ах, на которых могу накладываться свои политики по хранению.

#### Ceph

- Open-source
- S3 interface
- Известны промышленные инсталляции на десятки петабайт (OVH, DigitalOcean)

#### Ceph. CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data

1. __Распределение данных__: обеспечивает равномерное распределение данных между всеми доступными узлами
2. __Отказоустойчивость__: гарантирует, что данные дублируются на различных узлах, чтобы обеспечить доступность данных в случае сбоя одного или нескольких узлов
3. __Масштабируемость__: поддерживает добавление новых узлов и динамическое изменение конфигурации
4. __Управление ресурсами__: позволяет учитывать различные характеристики и ёмкости узлов для оптимального распределения данных

![[Pasted image 20250121014906.png]]


#### Ceph. CRUSH. Компоненты CRUSH-алгоритма

1. __CRUSH Map__. Основной элемент алгоритма, представляющий топологию кластера, включая информацию обо всех узлах, устройствах хранения, пулах и политике репликации:
	- Узлы: включают сервера и диски, которые участвуют в хранении данных
	- Правила (rules): определяют, как и где реплицировать данные
2. __Функция хеширования__: используется для определения местоположения объектов данных. Она принимает на вход идентификатор объекта и карту CRUSH, чтобы вернуть список узлов, на которых должны храниться данные
3. __Политики размещения__: включают правила, которые определяют, как распределять данные по узлам, учитывая такие факторы, как отказоустойчивость, latency и балансировка нагрузки.
4. __Модели отказов__: описывают возможные точки отказа в системе (например, уровень диска, сервера, стойки и т.д.) и их влияние на доступность данных.

#### NoSQL. Apache Cassandra

YTsaurus построена поверх Cypress (Кипариса) - отказоустойчивого древовидного стораджа, возможности которого тезисно можно описать следующим образом:
- Древовидны namesapce, узлами которого являются директории, таблицы (структурированные или полуструктурированные данные) и файлы (неструктурированные данные)
- Прозрачное шардироваине больших табличных данных на чанки, которое позволяет работать с таблицей как с единой сущностью, не думая о деталях её хранения.
- Поддержка колоночного и строчного механизмов хранения табличных данных
- Поддержка erasure кодирования

![[Pasted image 20250121020040.png]]

__CHYT__ - технология, которая позволяет выставить наружу ClickHouse натуру для Кипариса

**Полезные материалы:** 

- [https://itchronicles.com/what-is-big-data/](https://itchronicles.com/what-is-big-data/)
- [Knowledge Base of Relational and NoSQL Database Management Systems](https://db-engines.com/en/ranking)
- [Введение в фундаментальные принципы и основы Apache Cassandra](https://www.youtube.com/watch?v=Ae4GABykRoM)
- [Распределённый высоконагруженный feature store ОК](https://www.youtube.com/watch?v=UHI7JHUHD0s)
- [The Google File System: Paper](https://static.googleusercontent.com/media/research.google.com/ru//archive/gfs-sosp2003.pdf)
- [Обзор форматов данных](https://medium.com/m/global-identity-2?redirectUrl=https%3A%2F%2Fblog.clairvoyantsoft.com%2Fbig-data-file-formats-3fb659903271)
- [AWS re:Invent 2023 — Dive deep on Amazon S3](https://www.youtube.com/watch?v=sYDJYqvNeXU)
- [OK S3: cтроим cистему cами](https://www.youtube.com/watch?v=N3mbocqCtsk) 
- [Сeph Usages Survey](https://www.linkedin.com/pulse/surprising-results-from-ceph-survey-evan-miller/)
- [CRUSH Algorithm](https://ceph.io/assets/pdfs/weil-crush-sc06.pdf)
- leppman M. Designing  Data-Intensive Applications:  The Big Ideas Behind Reliable,  Scalable, and Maintainable  Systems
- White T. Hadoop:  The Definitive Guide